---
title: "DAS-group-17"
format: pdf
editor: visual
---

## Import Data

```{r}
data = read.csv("dataset17.csv")
any(is.na(data))
```

## Library the Packages

```{r}
#| warning: false
#| message: false
library(tidyverse)
library(moderndive)
library(gapminder)
library(sjPlot)
library(stats)
library(jtools)
library(gridExtra)
library(MASS)
library(pscl)
library(survival)
library(fitdistrplus)
library(gt)
library(vcd)
```

## Introduction

The data we obtained was a part of data from the Dallas animal shelter data. The data given included 1678 observations including the variables with 6 category variables and 1 numerical variable.

Animal_type: 5 types of animals in the shelter.

Month: the month when the animal was admitted to the shelter.

Year: the year when the animal was admitted to the shelter.

Intake_type: 3 different reasons for why the animal comes to the shelter.

Outcome_type: 5 different results after the animal has finished assistance in the shelter.

Chip_status: The status for the animal's chip status.

Time_at_shelter: The time for the animal to stay in the shelter.

In particular, this report presents numerical and graphical summaries of the data from the shelter for 7 different variables. A general linear model would be also fitted for the data, judging by some criteria statistics.

## Explanatory Data analysis

At the beginning of the EDA, we found that the year and month should be a category variable, so we need to change them first.

```{r}
data$month = factor(data$month)
data$year = factor(data$year)

```

### Summary Information

As the only numerical variables in this data, time_at_shelter should be consider with some summary statistics.

```{r}
#| label: summary statistics for time_at_shelter
summary1 = data%>%  
  summarize('Mean' = mean(time_at_shelter),
  'Median' = median(time_at_shelter),
  'St.Dev' = sd(time_at_shelter))%>%
mutate(Variable = "time_at_shelter")
summary2 = data%>%
  summarize(
            'IQR' = quantile(time_at_shelter,0.75)-quantile(time_at_shelter,0.25),
            'Min' = min(time_at_shelter),
            'Max' = max(time_at_shelter))%>%
mutate(Variable = "time_at_shelter")
```

```{r}
#| label: tbl-summarize_the_information_from_time_at_shelter_1
#| tbl-cap: Summary information of time_at_shelter part 1
#| warning: false
summary1%>%
  dplyr::select(Variable,everything())%>%
  gt()%>%
  fmt_number(columns = c(Mean, Median, St.Dev), decimals = 2) %>%
tab_style(style = cell_text(weight = "bold"),
locations = cells_column_labels())
```

```{r}
#| label: tbl-summarize_the_information_from_time_at_shelter_2
#| tbl-cap: Summary information of time_at_shelter part 2
#| warning: false
summary2%>%
  dplyr::select(Variable,everything())%>%
  gt()%>%
  fmt_number( decimals = 2) %>%
tab_style(style = cell_text(weight = "bold"),
locations = cells_column_labels())
  
```

According to @tbl-summarize_the_information_from_time_at_shelter_2, we can find that the mean of the time_at_shelter is not equal to median, the variance of time_at_shelter is much larger than the mean. This situation should be consider more in the part of formal analysis.

### Graphical Summaries

```{r}
#| label: fig-Histogram_for_time_at_shelter
#| fig-cap: Frequency Distribution for time at shelter
ggplot(data,aes(x = time_at_shelter))+
  geom_histogram(col = "white",fill = "steelblue")
```

From the @fig-Histogram_for_time_at_shelter and @tbl-summarize_the_information_from_time_at_shelter_2, the distribution for time_at_shelter should not be the poisson distribution. With data being overly dispersed, we could consider the time_at_shelter as a negative binomial distribution.

Based on data, it can be observed that the remaining six variables are categorical variables. Therefore, we can examine the distribution of categories by plotting bar plots.

```{r}
#| label: fig-bar_plot_for_categorical_variables
#| fig-cap: bar plots for categorical variables
a = ggplot(data,aes(x = animal_type))+
  geom_bar(fill = "steelblue")+
  theme(axis.text.x = element_text(size = 5))
b = ggplot(data,aes(x = month))+
  geom_bar(fill = "steelblue")
c = ggplot(data,aes(x = year))+
  geom_bar(fill = "steelblue")
d = ggplot(data,aes(x = intake_type))+
  geom_bar(fill = "steelblue")+
  theme(axis.text.x = element_text(size = 5))
e = ggplot(data,aes(x = outcome_type))+
  geom_bar(fill = "steelblue")+
  theme(axis.text.x = element_text(size = 5))
f = ggplot(data,aes(x = chip_status))+
  geom_bar(fill = "steelblue")+
  theme(axis.text.x = element_text(size = 5))
grid.arrange(a,b,c,d,e,f,nrow = 3)
```

The first figure in @fig-bar_plot_for_categorical_variables is a bar plot for the variable called animal_type, which shows that almost all the observations are cat and dog. With a similar situation, In the variable called outcome_type, the majority of the data are concentrated in three categories: adoption, euthanasia, and return to owner, with very few observations in the other two categories. We could also find the same situation in the bar plot for chip_status and intake_type, where only a very small portion of the data falls into the "CONFISCATED" and "UNABLE TO SCAN" category.

In the bar plot for months, we find that the data for June, July, and August are more abundant compared to other months.

Besides, the number of observations from 2016 is much less than the number of observations from 2017.

```{r}
#| label: fig-box_plot_for_categorical_variables
#| fig-cap: box plots for categorical variables
boxplot1 = ggplot(data,aes(x = animal_type,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))+
  theme(axis.text.x = element_text(size = 5))
boxplot2 = ggplot(data,aes(x = month,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))
boxplot3 = ggplot(data,aes(x = year,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))
boxplot4 = ggplot(data,aes(x = intake_type,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))+
  theme(axis.text.x = element_text(size = 5))
boxplot5 = ggplot(data,aes(x = outcome_type,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))+
  theme(axis.text.x = element_text(size = 5))
boxplot6 = ggplot(data,aes(x = chip_status,y = time_at_shelter))+
  geom_boxplot()+
  coord_cartesian(ylim = c(0,20))+
  theme(axis.text.x = element_text(size = 5))
grid.arrange(boxplot1,boxplot2,boxplot3,boxplot4,boxplot5,boxplot6,nrow = 3)
```

From @fig-box_plot_for_categorical_variables, with a similar situation, we can see the means of the various categories are not the same in the variables of animal_type,intake_type, outcome_type, and chip_status.Conversely, the means of the time-based categorical variables are almost identical.

### Correlation between Explanatory variables

```{r}
#| label: tbl-correlation-between-variables
#| tbl-cap: Correlation between Explanatory variables
cramersV <- matrix(0, nrow = 6,ncol = 6)
for (i in 1:6) {
  for (j in 1:i) {
    if (i != j) {
      assocStats <- assocstats(table(data[,i], data[,j]))
      cramersV[i,j] <- assocStats$cramer
      cramersV[j,i] <- assocStats$cramer 
    } else {
      cramersV[i,j] <- 1 
    }
  }
}
cramersV = as.data.frame(cramersV)
colnames(cramersV) = colnames(data[,1:6])
rownames(cramersV) = colnames(data[,1:6])
cramersV%>%
  kableExtra::kable()
```

Since the @tbl-correlation-between-variables demonstrates the correlation coefficients between explanatory variables, we can clearly see a high correlation between month and year,which means that the variable of year could be indicated totally by the variable of month. So let's see more information from this two variables.

Based on the situation, we suspect this is because some of the months fall in 2016, while the remaining months are in 2017.

To clearly present the situation described above with the data, we will transform the month data into a numerical variable, adding 12 to the months of 2017, to illustrate the sequential information of the month variable.

```{r}
data$month = as.numeric(data$month)
data$new_month = ifelse(data$year == "2017",data$month+12,data$month)
```

```{r}
#| label: fig-new_month
#| fig-cap: barplot for new month variable
ggplot(data,aes(x = new_month))+
  geom_bar(fill = "steelblue")
```

### Create new data

```{r}
#| label: create new data
new_data = data%>%
  dplyr::select(animal_type,new_month,intake_type,outcome_type,chip_status,time_at_shelter)
```

## Formal Analysis

### Criteria statistics

$$
BIC = \ln(n)k - 2\ln(\hat{L})
$$

$$
AIC = 2k - 2\ln(\hat{L})
$$

### GLM.NB Model

Since in the EDA part we found that the target variable don't follow the poisson distribution, the time_at_shelter also show the information that the variance of the variable is much larger than the mean, with a significantly over dispersed. So in this case, we may consider the general linear model for negtive binomial distribution at first.

```{r}
#| label: glm.nb model fitted
glmnb = glm.nb(time_at_shelter~intake_type+outcome_type,new_data)
```

```{r}
#| label: tbl-glmnb-model-coefficient
#| tbl-cap: coefficient table for negative binomial GLM model
coefficients(summary(glmnb))%>%
  kableExtra::kable()
```

```{r}
#| label: tbl-glmnb-model-criterial-statistics
#| tbl-cap: criterial statistics for model
cri = as.data.frame(c(BIC(glmnb),AIC(glmnb)))
rownames(cri) = c("BIC","AIC");colnames(cri) = c("num")
cri%>%
  kableExtra::kable()
```

According to the @tbl-glmnb-model-coefficient and @tbl-glmnb-model-criterial-statistics, we could find that the model coefficient of outcome_typeFOSTER is not significant enough, Since we set the alpha equal to 0.05. This model's BIC is the smallest one in the models with different combinations of explanatory variables

```{r}
#| label: fig-residual-versus-fitted-value
#| fig-cap: residual vs fitted value
residual = residuals(glmnb)
index = c(1:length(residuals(glmnb)))
predict = predict(glmnb)
regression_glmnb = as.data.frame(cbind(index,residual,predict))
colnames(regression_glmnb) = c("index","residual","predict")
ggplot(regression_glmnb,aes(x = predict,y = residual))+
  geom_jitter(alpha = 0.5)+
  geom_hline(yintercept = 0,col = "steelblue",lwd = 1)
```

```{r}
#| label: fig-histogram-for-model-residuals
#| fig-cap: histogram for model residuals
ggplot(regression_glmnb,aes(x = residual))+
  geom_histogram(bins = 30,col = "white",fill = "steelblue")
```

After observing the @fig-residual-versus-fitted-value and @fig-histogram-for-model-residuals, this model can barely pass the residual assumptions.

$$
\begin{aligned}
\log(\mu) = 3.74 - 1.95 \times \text{intake\_type}_{\text{OWNER SURRENDER}} - 1.44 \times \text{intake\_type}_{\text{STRAY}} \\
- 0.59 \times \text{outcome\_type}_{\text{DIED}} - 0.77 \times \text{outcome\_type}_{\text{EUTHANIZED}} \\
- 0.09 \times \text{outcome\_type}_{\text{FOSTER}} - 1.75 \times \text{outcome\_type}_{\text{RETURN TO OWNER}}
\end{aligned}
$$

### Zero-inflated Model

While in the EDA part, There are a considerable amount of zero contained in the data. With this situation, the zero-inflated model for negative binomial distribution and the hurdle model would also be tried in our research.

```{r}
#| label: zero-inflated model fitted
zeromodel <- zeroinfl(time_at_shelter ~ new_month+intake_type + outcome_type|1,
                     data = new_data, 
                     dist = "negbin")
```

```{r}
#| label: tbl-zeromodel-criterial-statistics
#| tbl-cap: zero
cri = as.data.frame(c(BIC(zeromodel),AIC(zeromodel)))
rownames(cri) = c("BIC","AIC");colnames(cri) = c("num")
cri%>%
  kableExtra::kable()
```

```{r}
#| label: tbl-zeromodel-coefficient
#| tbl-cap: coefficient table for zero-inflated model
coefficients(summary(zeromodel))%>%
  kableExtra::kable()
```

After observing the @tbl-zeromodel-coefficient and @tbl-zeromodel-criterial-statistics, This zero-inflated model's BIC is the smallest one in the models with different combinations. While they also demonstrated the coefficient of outcome_typeFOSTER is not significant, with a situation tha the p value of this coefficient is much larger than 0.05.

```{r}
#| label: fig-residual-versus-fitted-value-zeromodel
#| fig-cap: residual vs fitted value
index = c(1:length(residuals(zeromodel)))
predict = predict(zeromodel)
residual = residuals(zeromodel)
regression_zero = as.data.frame(cbind(index,residual,predict))
colnames(regression_zero) = c("index","residual","predict")
ggplot(regression_zero,aes(x = residual,y = predict))+
  geom_point()+
  geom_hline(yintercept = 0,lwd = 1)
```

```{r}
#| label: fig-histogram-for-model-residuals-zeromodel
#| fig-cap: histogram for zero inflect model residuals
ggplot(regression_zero,aes(x = residual))+
  geom_histogram(color = "white", fill = "steelblue")
```

However, the @fig-residual-versus-fitted-value-zeromodel shows a extreme situation of the residuals, Since all the residuals is larger than 0, The assumption that the residuals have a mean of zero is not met. We don't consider this model is suitable for the data we obtain.

$$
\begin{aligned}
\log(\mu) = 4.03 - 0.02 \times \text{new\_month} - 1.90 \times \text{intake\_type}_\text{OWNER SURRENDER} \\
- 1.40 \times \text{intake\_type}_\text{STRAY} - 0.57 \times \text{outcome\_type}_\text{DIED} \\
- 0.71 \times \text{outcome\_type}_\text{EUTHANIZED} - 0.03 \times \text{outcome\_type}_\text{FOSTER} \\
- 1.69 \times \text{outcome\_type}_\text{RETURN TO OWNER}
\end{aligned}
$$

### Hurdle Model

Hurdle model could be also considered with a situation that the data contain lots of zero. So we also fit a hurdle model for the data.

```{r}
#| label: hurdle model fitted
hurdle_model <- hurdle(time_at_shelter ~ new_month+intake_type+outcome_type| intake_type+outcome_type, data = new_data, 
                       dist = "negbin", zero.dist = "binomial")
```

```{r}
#| label: tbl-coefficient-of-hurdle-model
#| tbl-cap: coefficient table of hurdle model
coefficients(summary(hurdle_model))%>%
  kableExtra::kable()
```

```{r}
#| label: tbl-hurdle-model-criterial-statistics
#| tbl-cap: hurdle model coefficient table
cri = as.data.frame(c(BIC(hurdle_model),AIC(hurdle_model)))
rownames(cri) = c("BIC","AIC");colnames(cri) = c("num")
cri%>%
  kableExtra::kable()
```

With a consideration of @tbl-coefficient-of-hurdle-model\@tbl-coefficient-of-hurdle-model and @tbl-coefficient-of-hurdle-model, the performance of the hurdle model is the best among these three models. The coefficient of outcome_typeFOSTER is not significant across all three models.

```{r}
#| label: fig-residual-versus-fitted-value-hurdle-model
#| fig-cap: residual vs fitted value
residual = residuals(hurdle_model)
index = c(1:length(residuals(hurdle_model)))
predict = predict(hurdle_model)
regression_hurdle = as.data.frame(cbind(index,residual,predict))
colnames(regression_hurdle) = c("index","residual","predict")
ggplot(regression_hurdle,aes(x = predict,y = residual))+
  geom_jitter(alpha = 0.5)+
  geom_hline(yintercept = 0,col = "steelblue",lwd = 1)
```

```{r}
#| label: fig-histogram-for-model-residuals-hurdle-model
#| fig-cap: histogram for zero inflect model residuals
ggplot(regression_hurdle,aes(x = residual))+
  geom_histogram(bins = 32,col = "white",fill = "steelblue")
```

Observing from @fig-residual-versus-fitted-value-hurdle-model and @fig-histogram-for-model-residuals-hurdle-model, we may consider that the model roughly passes the zero-mean assumption and the constant variance assumption in the residual test, but through the histogram, the model may not pass the assumption that the residuals are normally distributed.

$$
\begin{aligned}
\log(\mu) = 3.49 - 0.02 \times \text{new\_month} - 1.34 \times \text{intake\_type}_\text{OWNER SURRENDER} \\
- 0.92 \times \text{intake\_type}_\text{STRAY} - 0.44 \times \text{outcome\_type}_\text{DIED} \\
- 0.29 \times \text{outcome\_type}_\text{EUTHANIZED} + 0.22 \times \text{outcome\_type}_\text{FOSTER} \\
- 1.10 \times \text{outcome\_type}_\text{RETURN TO OWNER}
\end{aligned}
$$ $$
\begin{aligned}
\log \left( \frac{\pi}{1 - \pi} \right) = 7.81 - 4.39 \times \text{intake\_type}_\text{OWNER SURRENDER} - 3.55 \times \text{intake\_type}_\text{STRAY} \\
- 2.59 \times \text{outcome\_type}_\text{DIED} - 3.51 \times \text{outcome\_type}_\text{EUTHANIZED} \\
- 3.01 \times \text{outcome\_type}_\text{FOSTER} - 4.37 \times \text{outcome\_type}_\text{RETURN TO OWNER}
\end{aligned}
$$

## Conclusion 

The negative binomial model was selected as the final model by analyzing and testing the model .

From this model it is possible to derive intake type and outcome type as factors that influence the number of days an animal spends in the shelter before their final outcome is decided. It is worth mentioning that month can also greatly influence the number of days an animal spends in the shelter in the Hurdle model.

The intercept in the model means that the expected log count of time_at_shelter is 3.7436 when the reason for the animal being admitted to the shelter is confiscated and the final outcome of the admitted animal is adoption. The coefficient of -1.9517 for owner surrender indicates that for each unit increase in this category of the reason for the animal being admitted to the shelter is owner surrender compared to the other categories, the log count of time_at\_ shelter decreases on average by about 1.9517. The rest of the coefficients can be interpreted similarly.

According to the Bayesian Information Criterion, although other variables also contain information to predict time_at_shelter, the information contained in the two variables intake_type and outcome_type is relatively more substantial compared to the other variables.
